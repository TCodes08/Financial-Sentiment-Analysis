{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2731,
     "status": "ok",
     "timestamp": 1749723953703,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "4WW7qhpTuBsQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tecsongacrama/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tecsongacrama/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tecsongacrama/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer, default_data_collator,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "from preprocessing import FinancialTweetPreprocessor\n",
    "from evaluation_transformer import evaluate_transformer\n",
    "from initial_balanced_dataset import create_balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49279,
     "status": "ok",
     "timestamp": 1749724003181,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "3IhiE3VsuSm-",
    "outputId": "4dee3b95-9b8b-4121-a53e-99956ec0e2e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both train/val and test datasets already exist. Skipping creation.\n",
      "(47106, 2)\n",
      "Preprocessing DataFrame...\n",
      "\n",
      "Processed DataFrame:\n",
      "                                      processed_text  sentiment  ticker_count  \\\n",
      "0          upholding perhaps pushing price upwards .          1             0   \n",
      "1  michael k . wirth sell 52,500 share chevron co...          2             1   \n",
      "2  would buy aap buy c growth . aap sell ipads ip...          1             0   \n",
      "3  economic expert believe current interest rate ...          0             0   \n",
      "4                    era financial boom over forever          2             0   \n",
      "\n",
      "   mention_count  url_count  token_count  exclamation_count  question_count  \n",
      "0              0          0            6                  0               0  \n",
      "1              0          0           12                  0               0  \n",
      "2              0          0           15                  0               0  \n",
      "3              0          0           10                  0               0  \n",
      "4              0          0            5                  0               0  \n",
      "\n",
      "All columns in processed DataFrame:\n",
      "['tweet', 'sentiment', 'processed_text', 'ticker_count', 'mention_count', 'url_count', 'token_count', 'exclamation_count', 'question_count']\n",
      "Number of zeros per column:\n",
      "tweet                    0\n",
      "sentiment            15702\n",
      "processed_text           0\n",
      "ticker_count         29186\n",
      "mention_count        40628\n",
      "url_count            37076\n",
      "token_count              2\n",
      "exclamation_count    43507\n",
      "question_count       44121\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create dataset (skips if dataset already exists)\n",
    "create_balanced_dataset()\n",
    "# Load Data\n",
    "df = pd.read_csv('../../dataset/initial_balanced_tweets.csv')\n",
    "print(df.shape)\n",
    "# Preprocess\n",
    "print(\"Preprocessing DataFrame...\")\n",
    "preprocessor = FinancialTweetPreprocessor()\n",
    "df_preprocessed = preprocessor.preprocess_dataset(df, 'tweet')\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"\\nProcessed DataFrame:\")\n",
    "print(df_preprocessed[['processed_text', 'sentiment', 'ticker_count', 'mention_count',\n",
    "                       'url_count', 'token_count', 'exclamation_count', 'question_count']].head())\n",
    "print(\"\\nAll columns in processed DataFrame:\")\n",
    "print(df_preprocessed.columns.tolist())\n",
    "# Count zeros in every column of df_preprocessed\n",
    "zero_counts = (df_preprocessed == 0).sum()\n",
    "print(\"Number of zeros per column:\")\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1749724003232,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "GuVmNa1dzzUS",
    "outputId": "d34c7e09-8f19-4a9d-cd9e-2af5effa1d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 41683 samples\n",
      "Testing set size: 10421 samples\n"
     ]
    }
   ],
   "source": [
    "X = df_preprocessed[['processed_text', 'ticker_count', 'mention_count',\n",
    "                 'url_count', 'token_count']]\n",
    "y = df_preprocessed['sentiment']\n",
    "\n",
    "# Split the Data into Training and Testing Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Validation set size: {len(X_val)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLOADING & PREPROCESSING TEST SET\")\n",
    "df_test = pd.read_csv(\"../../dataset/test_set.csv\")\n",
    "# Preprocess text\n",
    "preprocessor = FinancialTweetPreprocessor()\n",
    "df_test = preprocessor.preprocess_dataset(df_test, text_column='tweet')\n",
    "# Prepare inputs\n",
    "X_test = df_test[['processed_text', 'ticker_count', 'mention_count', 'url_count', 'token_count']]\n",
    "y_test = df_test['sentiment']\n",
    "print(f\"Testing set size: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749724023279,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "dr99yMmc28K8",
    "outputId": "aa713850-c97f-40d9-ac36-5ab152d73066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration\n",
      "Class distribution in training set:\n",
      "sentiment\n",
      "0    13895\n",
      "1    13894\n",
      "2    13894\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in test set:\n",
      "sentiment\n",
      "0    3473\n",
      "1    3474\n",
      "2    3474\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ------ FinBert + QLoRA ------\n",
    "# Re-Check data format and class distribution\n",
    "print(f\"\\nDataset Configuration\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nClass distribution in validation set:\")\n",
    "print(y_val.value_counts().sort_index())\n",
    "print(f\"\\nClass distribution in testing set:\")\n",
    "print(y_test.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "868d89b7dacc4442b555fcbdbb046548",
      "9d78adf882614af8943b8adbcbee04f1",
      "acaeb50f672b4dbfa78d2fbec8c202fc",
      "d151b7675e1f4abcb0043c665dccb5fe",
      "b7e0739e66a44e10934e35e30f61080f",
      "fcc95a2c8fc64633ba3a6bc75b1e6517",
      "0df501453c1c487da2cac05a9825fb1f",
      "eb567b800dd24be1b2412c73eb42d038",
      "eb3b5cc72bc74b90938e17ea34cf3174",
      "b07d24c526b74f009fecc3f58738e7cc",
      "81c5a9dd421249a1bd34c57cf86a7208"
     ]
    },
    "executionInfo": {
     "elapsed": 15823,
     "status": "ok",
     "timestamp": 1749724039103,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "i2zXpeai8Hr9",
    "outputId": "eba0e7c5-2353-43de-a88a-f2f5ba8b6a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOADING FINBERT AND CONFIGURING LORA\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m bnb_config = BitsAndBytesConfig(\n\u001b[32m     11\u001b[39m     load_in_4bit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     12\u001b[39m     bnb_4bit_quant_type=\u001b[33m\"\u001b[39m\u001b[33mnf4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     bnb_4bit_compute_dtype=torch.bfloat16\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Load the base model with the quantization config\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m base_model = \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProsusAI/finbert\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Important for QLoRA\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m base_model = prepare_model_for_kbit_training(base_model)\n\u001b[32m     26\u001b[39m lora_config = LoraConfig(\n\u001b[32m     27\u001b[39m     r=\u001b[32m16\u001b[39m,  \u001b[38;5;66;03m# rank\u001b[39;00m\n\u001b[32m     28\u001b[39m     lora_alpha=\u001b[32m32\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     task_type=TaskType.SEQ_CLS,\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS_Projects/financial_sentimentAnalysis/sentimentAnalysis-venv/lib/python3.13/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS_Projects/financial_sentimentAnalysis/sentimentAnalysis-venv/lib/python3.13/site-packages/transformers/modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS_Projects/financial_sentimentAnalysis/sentimentAnalysis-venv/lib/python3.13/site-packages/transformers/modeling_utils.py:4390\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4387\u001b[39m     hf_quantizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4390\u001b[39m     \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4394\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4396\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4397\u001b[39m     torch_dtype = hf_quantizer.update_torch_dtype(torch_dtype)\n\u001b[32m   4398\u001b[39m     device_map = hf_quantizer.update_device_map(device_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS_Projects/financial_sentimentAnalysis/sentimentAnalysis-venv/lib/python3.13/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:76\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.validate_environment\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     73\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing `bitsandbytes` 4-bit quantization requires Accelerate: `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m     )\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_bitsandbytes_available():\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     77\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m     )\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_bnb_backend_availability\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n",
      "\u001b[31mImportError\u001b[39m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`"
     ]
    }
   ],
   "source": [
    "print(\"\\nLOADING FINBERT AND CONFIGURING LORA\")\n",
    "\n",
    "# Load FinBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "# Define BitsAndBytes config for 4-bit loading\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load the base model with the quantization config\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"ProsusAI/finbert\",\n",
    "    num_labels=3,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\" # Important for QLoRA\n",
    ")\n",
    "\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "\n",
    "# Apply LoRA to the base model\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "print(\"\\nLoRA configuration applied!\")\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1749724039124,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "cKICcFmC67aO",
    "outputId": "4cae2d9e-04b9-4cef-8b78-ad7f52622ba6"
   },
   "outputs": [],
   "source": [
    "print(\"\\nCREATING CUSTOM MODEL WITH METADATA FEATURES\")\n",
    "\n",
    "class FinBERTWithMetadata(nn.Module):\n",
    "    def __init__(self, lora_model, num_features=4, num_labels=3):\n",
    "        super().__init__()\n",
    "        self.lora_model = lora_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(768 + num_features, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, features=None):\n",
    "        # Get BERT outputs\n",
    "        bert_outputs = self.lora_model.base_model.model.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        # Get pooled output\n",
    "        pooled_output = bert_outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        # If features provided, concatenate them\n",
    "        if features is not None:\n",
    "            combined = torch.cat([pooled_output, features], dim=1)\n",
    "            logits = self.classifier(combined)\n",
    "        else:\n",
    "            # Fallback for inference without features\n",
    "            logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "# Initialize the combined model\n",
    "model = FinBERTWithMetadata(lora_model)\n",
    "print(\"Custom model with metadata features created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192,
     "referenced_widgets": [
      "6d31d7ce24ff400b80d7ef152f02d00c",
      "f712b338ecf54328a0dfe449d2ad1d13",
      "f3674b014e3e4518a0e07ed11515eadb",
      "d6bd18aaaf864890b2ab5f370eaa9d14",
      "c6d4ac2974ec42218e3120fde1cae24d",
      "b8f1c9fa8f144c788fa8b530ae37122e",
      "3f8720902a8d4c9b877c81956ad792f8",
      "cadd7ea56e5d4dc19120601e78a800c5",
      "20260c7516fe4aeeb5cac2cffeb6afb2",
      "2e19234238ad49dbb5089de5507682f0",
      "c1796a9175c941839dc97f047cdf3de5"
     ]
    },
    "executionInfo": {
     "elapsed": 8914,
     "status": "ok",
     "timestamp": 1749724048039,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "TCVtIOOG8rQL",
    "outputId": "c487f676-38e4-4809-8b03-77469db57ba8"
   },
   "outputs": [],
   "source": [
    "print(\"\\nPREPARING DATA WITH TEXT AND METADATA\")\n",
    "\n",
    "# Define config\n",
    "feature_columns = ['ticker_count', 'mention_count', 'url_count', 'token_count']\n",
    "\n",
    "# Scale metadata features\n",
    "scaler = StandardScaler()\n",
    "train_features = X_train[feature_columns].values\n",
    "val_features = X_val[feature_columns].values\n",
    "test_features = X_test[feature_columns].values\n",
    "\n",
    "print(\"Scaling metadata features...\")\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "val_features_scaled = scaler.transform(val_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "print(\"Feature statistics (after scaling):\")\n",
    "print(f\"Mean: {train_features_scaled.mean(axis=0)}\")\n",
    "print(f\"Std: {train_features_scaled.std(axis=0)}\")\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "print(\"\\nTokenizing text data...\")\n",
    "train_encodings = tokenize_function(X_train['processed_text'].tolist())\n",
    "val_encodings = tokenize_function(X_val['processed_text'].tolist())\n",
    "test_encodings = tokenize_function(X_test['processed_text'].tolist())\n",
    "\n",
    "# Define dataset class\n",
    "class TextAndFeaturesDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, features):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        item['features'] = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = TextAndFeaturesDataset(train_encodings, y_train.tolist(), train_features_scaled)\n",
    "val_dataset = TextAndFeaturesDataset(val_encodings, y_val.tolist(), val_features_scaled)\n",
    "test_dataset = TextAndFeaturesDataset(test_encodings, y_test.tolist(), test_features_scaled)\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)} samples\")\n",
    "print(f\"Validation set size: {len(val_dataset)} samples\")\n",
    "print(f\"Test set size: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1749724048085,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "xIYov5Xu9BUY",
    "outputId": "f350deef-5c8c-4eb5-f06d-2db67d54aef5"
   },
   "outputs": [],
   "source": [
    "print(\"SETTING UP CUSTOM TRAINER\")\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        features = inputs.pop(\"features\")\n",
    "\n",
    "        # Forward pass with features\n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            features=features\n",
    "        )\n",
    "\n",
    "        # Compute loss\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(outputs.view(-1, 3), labels.view(-1))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        labels = inputs.pop(\"labels\") if \"labels\" in inputs else None\n",
    "        features = inputs.pop(\"features\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                features=features\n",
    "            )\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(outputs.view(-1, 3), labels.view(-1))\n",
    "\n",
    "        return (loss, outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 659195,
     "status": "ok",
     "timestamp": 1749732369327,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "J6NrWg0n9EyP",
    "outputId": "e156736a-68a9-458f-8825-febc06ab760a"
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../models/finbertqlora/finbert-qlora-metadata-results\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    bf16=True,\n",
    "    #fp16=True if torch.cuda.is_available() else False,\n",
    "    seed=42,\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_steps=None,\n",
    "    save_strategy=\"no\",\n",
    "    disable_tqdm=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"TRAINING MODEL\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 686693,
     "status": "ok",
     "timestamp": 1749733056026,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "tpdmrHwD_hcY",
    "outputId": "8a4adea9-6739-49b9-dc04-3b9cfbd7ad05"
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(\"EVALUATE ON TEST SET\")\n",
    "evaluate_transformer(trainer, train_dataset, test_dataset, y_train, y_test, model, save_dir=\"../../evaluation/baseline/finbert_qlora_eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5220,
     "status": "ok",
     "timestamp": 1749733061249,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "JOQOlnmX_mTw",
    "outputId": "759fbb26-4fb6-4934-d8e9-47ad4678815f"
   },
   "outputs": [],
   "source": [
    "print(\"SAVING FINAL MODEL AND COMPONENTS\")\n",
    "\n",
    "save_dir = \"../../models/v1-1/baseline/finbert_qlora/final\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save model state (includes custom classifier + LoRA)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler': scaler,\n",
    "    'feature_columns': feature_columns,\n",
    "    'lora_config': lora_config,\n",
    "}, os.path.join(save_dir, 'model_complete.pth'))\n",
    "\n",
    "# Save tokenizer and LoRA adapter separately\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "model.lora_model.save_pretrained(os.path.join(save_dir, 'qlora_adapter'))\n",
    "\n",
    "print(f\"Saved to: {save_dir}\")\n",
    "print(\"Contents:\")\n",
    "print(\"  - model_complete.pth\")\n",
    "print(\"  - tokenizer/\")\n",
    "print(\"  - lora_adapter/\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0df501453c1c487da2cac05a9825fb1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20260c7516fe4aeeb5cac2cffeb6afb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e19234238ad49dbb5089de5507682f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f8720902a8d4c9b877c81956ad792f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d31d7ce24ff400b80d7ef152f02d00c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f712b338ecf54328a0dfe449d2ad1d13",
       "IPY_MODEL_f3674b014e3e4518a0e07ed11515eadb",
       "IPY_MODEL_d6bd18aaaf864890b2ab5f370eaa9d14"
      ],
      "layout": "IPY_MODEL_c6d4ac2974ec42218e3120fde1cae24d"
     }
    },
    "81c5a9dd421249a1bd34c57cf86a7208": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "868d89b7dacc4442b555fcbdbb046548": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d78adf882614af8943b8adbcbee04f1",
       "IPY_MODEL_acaeb50f672b4dbfa78d2fbec8c202fc",
       "IPY_MODEL_d151b7675e1f4abcb0043c665dccb5fe"
      ],
      "layout": "IPY_MODEL_b7e0739e66a44e10934e35e30f61080f"
     }
    },
    "9d78adf882614af8943b8adbcbee04f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcc95a2c8fc64633ba3a6bc75b1e6517",
      "placeholder": "​",
      "style": "IPY_MODEL_0df501453c1c487da2cac05a9825fb1f",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "acaeb50f672b4dbfa78d2fbec8c202fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb567b800dd24be1b2412c73eb42d038",
      "max": 437992753,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb3b5cc72bc74b90938e17ea34cf3174",
      "value": 437992753
     }
    },
    "b07d24c526b74f009fecc3f58738e7cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7e0739e66a44e10934e35e30f61080f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8f1c9fa8f144c788fa8b530ae37122e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1796a9175c941839dc97f047cdf3de5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6d4ac2974ec42218e3120fde1cae24d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cadd7ea56e5d4dc19120601e78a800c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d151b7675e1f4abcb0043c665dccb5fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b07d24c526b74f009fecc3f58738e7cc",
      "placeholder": "​",
      "style": "IPY_MODEL_81c5a9dd421249a1bd34c57cf86a7208",
      "value": " 438M/438M [00:07&lt;00:00, 71.6MB/s]"
     }
    },
    "d6bd18aaaf864890b2ab5f370eaa9d14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e19234238ad49dbb5089de5507682f0",
      "placeholder": "​",
      "style": "IPY_MODEL_c1796a9175c941839dc97f047cdf3de5",
      "value": " 438M/438M [00:08&lt;00:00, 69.6MB/s]"
     }
    },
    "eb3b5cc72bc74b90938e17ea34cf3174": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eb567b800dd24be1b2412c73eb42d038": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3674b014e3e4518a0e07ed11515eadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cadd7ea56e5d4dc19120601e78a800c5",
      "max": 437965908,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20260c7516fe4aeeb5cac2cffeb6afb2",
      "value": 437965908
     }
    },
    "f712b338ecf54328a0dfe449d2ad1d13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8f1c9fa8f144c788fa8b530ae37122e",
      "placeholder": "​",
      "style": "IPY_MODEL_3f8720902a8d4c9b877c81956ad792f8",
      "value": "model.safetensors: 100%"
     }
    },
    "fcc95a2c8fc64633ba3a6bc75b1e6517": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
