{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8363,
     "status": "ok",
     "timestamp": 1750621140018,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "2oT6fmLazj_q",
    "outputId": "fe84a16f-a249-4ba0-e4d8-d5f2d6cb819a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/590.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1750621737178,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "aFciQiiWkGY0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from preprocessing import FinancialTweetPreprocessor\n",
    "from evaluation_classical import evaluate_classical_model\n",
    "from initial_balanced_dataset import create_balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31221,
     "status": "ok",
     "timestamp": 1750621183659,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "X8qIC2ywaWTE",
    "outputId": "dbb2e1cf-a830-43b4-a081-15f8bdf08550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47106, 2)\n",
      "Preprocessing DataFrame...\n",
      "\n",
      "Processed DataFrame:\n",
      "                                      processed_text  sentiment  ticker_count  \\\n",
      "0          upholding perhaps pushing price upwards .          1             0   \n",
      "1  michael k . wirth sell 52,500 share chevron co...          2             1   \n",
      "2  would buy aap buy c growth . aap sell ipads ip...          1             0   \n",
      "3  economic expert believe current interest rate ...          0             0   \n",
      "4                    era financial boom over forever          2             0   \n",
      "\n",
      "   mention_count  url_count  token_count  exclamation_count  question_count  \n",
      "0              0          0            6                  0               0  \n",
      "1              0          0           12                  0               0  \n",
      "2              0          0           15                  0               0  \n",
      "3              0          0           10                  0               0  \n",
      "4              0          0            5                  0               0  \n",
      "\n",
      "All columns in processed DataFrame:\n",
      "['tweet', 'sentiment', 'processed_text', 'ticker_count', 'mention_count', 'url_count', 'token_count', 'exclamation_count', 'question_count']\n",
      "Number of zeros per column:\n",
      "tweet                    0\n",
      "sentiment            15702\n",
      "processed_text           0\n",
      "ticker_count         29186\n",
      "mention_count        40628\n",
      "url_count            37076\n",
      "token_count              2\n",
      "exclamation_count    43507\n",
      "question_count       44121\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create dataset (skips if dataset already exists)\n",
    "create_balanced_dataset()\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('../../dataset/initial_balanced_tweets.csv')\n",
    "print(df.shape)\n",
    "\n",
    "# Preprocess\n",
    "print(\"Preprocessing DataFrame...\")\n",
    "preprocessor = FinancialTweetPreprocessor()\n",
    "df_preprocessed = preprocessor.preprocess_dataset(df, 'tweet')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"\\nProcessed DataFrame:\")\n",
    "print(df_preprocessed[['processed_text', 'sentiment', 'ticker_count', 'mention_count',\n",
    "                       'url_count', 'token_count', 'exclamation_count', 'question_count']].head())\n",
    "print(\"\\nAll columns in processed DataFrame:\")\n",
    "print(df_preprocessed.columns.tolist())\n",
    "\n",
    "# Count zeros in every column of df_preprocessed\n",
    "zero_counts = (df_preprocessed == 0).sum()\n",
    "print(\"Number of zeros per column:\")\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750621183663,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "1vs4oLAza94S",
    "outputId": "b5271e9c-9686-4fb2-970a-a423e46b8ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 37684 samples\n",
      "Validation set size: 9422 samples\n"
     ]
    }
   ],
   "source": [
    "# Define Features (X) and Labels (y)\n",
    "# X will be a DataFrame containing both text and numerical metadata columns\n",
    "X = df_preprocessed[['processed_text', 'ticker_count', 'mention_count',\n",
    "                  'url_count', 'token_count', 'exclamation_count', 'question_count']]\n",
    "y = df_preprocessed['sentiment'] \n",
    "\n",
    "# Split the Data into Training and Validation Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Validation set size: {len(X_val)} samples\")\n",
    "\n",
    "# Load and Preprocess Test Set\n",
    "df_test = pd.read_csv(\"../../dataset/test_set.csv\")\n",
    "df_test = preprocessor.preprocess_dataset(df_test, text_column='tweet')\n",
    "X_test = df_test[['processed_text', 'ticker_count', 'mention_count',\n",
    "                  'url_count', 'token_count', 'exclamation_count', 'question_count']]\n",
    "y_test = df_test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750621183669,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "RLDTvsgLa_Qg",
    "outputId": "5900bad7-5294-4a83-b5df-fd4da31792d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Configuration\n",
      "\n",
      "Class distribution in training set:\n",
      "sentiment\n",
      "0    12562\n",
      "1    12561\n",
      "2    12561\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in validation set:\n",
      "sentiment\n",
      "0    3140\n",
      "1    3141\n",
      "2    3141\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Re-Check data format and class distribution\n",
    "print(f\"\\nDataset Configuration\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nClass distribution in validation set:\")\n",
    "print(y_val.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6948,
     "status": "ok",
     "timestamp": 1750621190617,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "Dgd3LoymvfjV",
    "outputId": "2dd7eea2-3c89-48a6-df5c-dfa14b8ec011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear SVM model...\n",
      "Linear SVM training complete.\n"
     ]
    }
   ],
   "source": [
    "# Define Preprocessing Steps for Different Column Types\n",
    "preprocessor_for_model = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Apply TF-IDF to 'processed_text'\n",
    "        ('text_vectorizer', TfidfVectorizer(max_features=20000, min_df=5, ngram_range=(1, 2)), 'processed_text'),\n",
    "        # Apply StandardScaler to metadata\n",
    "        ('num_scaler', StandardScaler(), ['ticker_count', 'mention_count', 'url_count',\n",
    "                                          'token_count', 'exclamation_count', 'question_count'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a Pipeline: Preprocessing + Model Training\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_for_model), # TF-IDF to text and scales metadata\n",
    "    ('svm_model', LinearSVC(random_state=42, C=0.5, max_iter=10000)) # Linear SVM\n",
    "])\n",
    "\n",
    "# Train the Pipeline\n",
    "print(\"\\nTraining Linear SVM model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Linear SVM training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295728,
     "status": "ok",
     "timestamp": 1750621488368,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "3mY5EdambUiY",
    "outputId": "a612aa19-e236-41ec-9363-90ed18718e74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATE ON TEST SET\n",
      "EVALUATING ON TEST SET\n",
      "     Precision (Macro Avg)  Recall (Macro Avg)  F1-Score (Macro Avg)  \\\n",
      "svm               0.740389            0.735894               0.73537   \n",
      "\n",
      "     Overall Accuracy  \n",
      "svm          0.735894  \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Neutral (0)       0.75      0.76      0.76      1666\n",
      " Bullish (1)       0.69      0.78      0.73      1666\n",
      " Bearish (2)       0.78      0.66      0.72      1666\n",
      "\n",
      "    accuracy                           0.74      4998\n",
      "   macro avg       0.74      0.74      0.74      4998\n",
      "weighted avg       0.74      0.74      0.74      4998\n",
      "\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "VALIDATION CURVE\n",
      "\n",
      "LEARNING CURVE\n",
      "\n",
      "Evaluation complete. Results saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"EVALUATE ON TEST SET\")\n",
    "evaluate_classical_model(pipeline, X_train, y_train, X_test, y_test,\n",
    "                         model_name=\"svm\", save_dir=\"../../evaluation/baseline/svm_eval\", param_name='svm_model__C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1750621742230,
     "user": {
      "displayName": "Timothy Tong",
      "userId": "04634270029715237152"
     },
     "user_tz": 420
    },
    "id": "P9930DS4JYEs",
    "outputId": "09c89b9b-76d8-4024-bca2-60dc652d273f"
   },
   "outputs": [],
   "source": [
    "# Save the entire pipeline (preprocessing + model)\n",
    "joblib.dump(pipeline, '../../models/v1-1/baseline/svm_pipeline.pkl')\n",
    "print(\"Model pipeline saved to ../../models/v1-1/baseline/svm_pipeline.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
